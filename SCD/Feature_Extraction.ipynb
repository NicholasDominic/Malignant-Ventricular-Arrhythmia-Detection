{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4HVEIEx1m36"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx1Vz9891osS"
      },
      "source": [
        "## Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzCdWxb3SiIW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4y-LqTs1ufi"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQKYwdNS1v8q"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj0cKSRW_Fi9"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDhnM6Wg13s4"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1JE6wZzXlUj"
      },
      "source": [
        "!pip install heartpy\n",
        "from heartpy import analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBsUwovk16m2"
      },
      "source": [
        "!pip install hrv-analysis\n",
        "import hrvanalysis\n",
        "from hrvanalysis import get_time_domain_features\n",
        "# from hrvanalysis.preprocessing import remove_ectopic_beats\n",
        "from hrvanalysis import get_frequency_domain_features\n",
        "from hrvanalysis import get_poincare_plot_features\n",
        "# from hrvanalysis.plot import plot_psd, plot_poincare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhT_8rv3TjaZ"
      },
      "source": [
        "!pip install pyhrv\n",
        "import pyhrv\n",
        "import pyhrv.nonlinear as nl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYAoKOG12epC"
      },
      "source": [
        "# R-Peak Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTu27TZiOd8H"
      },
      "source": [
        "def get_files(path):\n",
        "  files = []\n",
        "  for r, d, f in os.walk(path):\n",
        "      for file in f:\n",
        "          if 'channel_1.csv' in file:\n",
        "            files.append(file)\n",
        "  return files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUn7jVC53pe3"
      },
      "source": [
        "positive_path = \"/content/drive/My Drive/Signal/Positive-Peaklist/\"\n",
        "positive_files = get_files(positive_path)\n",
        "print(len(positive_files))\n",
        "\n",
        "negative_path = \"/content/drive/My Drive/Signal/Negative-Peaklist/\"\n",
        "negative_files = get_files(negative_path)\n",
        "print(len(negative_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rlpAjJS4I-D"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzJSJ4lw6kbi"
      },
      "source": [
        "## Slice Peaklist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYsyGBv6qd1"
      },
      "source": [
        "def get_sliced_peaklist(peaklist_df, time_duration, frequency_sampling):\n",
        "  if time_duration == 5: # 5 minutes duration\n",
        "    return peaklist_df['peaklist'].to_numpy()\n",
        "  end_sampling = 5 * 60 * frequency_sampling\n",
        "  start_sampling = (5-time_duration) * 60 * frequency_sampling\n",
        "  return peaklist_df[peaklist_df['peaklist'].between(start_sampling, end_sampling)]['peaklist'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZsHDklL49Vv"
      },
      "source": [
        "## RR Interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK6PSLr44_bw"
      },
      "source": [
        "def get_rr_interval(peaklist, frequency_sampling):\n",
        "  wd = analysis.calc_rr(peaklist, sample_rate = frequency_sampling)\n",
        "  return wd['RR_list']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQeYQGxPGO9O"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6zIC0XD-HPw"
      },
      "source": [
        "### Time Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdyZFrH45W0O"
      },
      "source": [
        "def outlier_count(rr_intervals, difference_percentage):\n",
        "  count = 0\n",
        "  length = len(rr_intervals)\n",
        "  for i in range(length-1):\n",
        "    if abs(rr_intervals[i] - rr_intervals[i+1]) > difference_percentage * rr_intervals[i]:\n",
        "      count += 1\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdk_t1oL-Ggk"
      },
      "source": [
        "time_domain = ['MeanNN','SDNN','RMSSD','pNN50','sdHR', 'Outlier']\n",
        "\n",
        "def get_time_domain_analysis_features(rr_interval):\n",
        "  result = {}\n",
        "  time_domain_features = get_time_domain_features(rr_interval)\n",
        "  features = {'MeanNN':'mean_nni',\n",
        "          'SDNN': 'sdnn',\n",
        "          'RMSSD': 'rmssd',\n",
        "          'pNN50': 'pnni_50',\n",
        "          'sdHR': 'std_hr'}\n",
        "  for description, key in features.items():\n",
        "    result[description] = time_domain_features[key]\n",
        "  result['Outlier'] = outlier_count(rr_intervals=rr_interval, difference_percentage=0.2)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVa-aLwiPIuH"
      },
      "source": [
        "### Frequency Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj-rR0m2PT_t"
      },
      "source": [
        "frequency_domain = ['VLF','LF','HF','LF/HF','aTotal','pVLF','pLF']\n",
        "\n",
        "def get_frequency_domain_analysis_features(rr_interval):\n",
        "  result = {}\n",
        "  # plot_psd(rr_interval)\n",
        "  frequency_domain_features = get_frequency_domain_features(rr_interval, method='welch')\n",
        "  features = {'VLF':'vlf',\n",
        "          'LF': 'lf',\n",
        "          'HF': 'hf',\n",
        "          'LF/HF': 'lf_hf_ratio',\n",
        "          'aTotal': 'total_power'}\n",
        "  for description, key in features.items():\n",
        "    result[description] = frequency_domain_features[key]\n",
        "  result['pVLF'] = result['VLF'] / result['aTotal'] * 100\n",
        "  result['pLF'] = result['LF'] / result['aTotal'] * 100\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvYk7pvjPNHR"
      },
      "source": [
        "### Non Linear Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P041dVrk55d7"
      },
      "source": [
        "import nolds\n",
        "import biosppy\n",
        "\n",
        "def new_dfa(nn=None, rpeaks=None, short=None, long=None, show=True, figsize=None, legend=True):\n",
        "\t\"\"\"Parameters\n",
        "\t----------\n",
        "\tnn : array\n",
        "\t\tNN intervals in [ms] or [s].\n",
        "\trpeaks : array\n",
        "\t\tR-peak times in [ms] or [s].\n",
        "\tshort : array, 2 elements\n",
        "\t\tInterval limits of the short term fluctuations (default: None: [4, 16]).\n",
        "\tlong : array, 2 elements\n",
        "\t\tInterval limits of the long term fluctuations (default: None: [17, 64]).\n",
        "\tshow : bool\n",
        "\t\tIf True, shows DFA plot (default: True)\n",
        "\tlegend : bool\n",
        "\t\tIf True, adds legend with alpha1 and alpha2 values to the DFA plot (default: True)\n",
        "\tReturns (biosppy.utils.ReturnTuple Object)\n",
        "\t------------------------------------------\n",
        "\t[key : format]\n",
        "\t\tDescription.\n",
        "\tdfa_short : float\n",
        "\t\tAlpha value of the short term fluctuations\n",
        "\tdfa_long : float\n",
        "\t\tAlpha value of the long term fluctuations\n",
        "\tdfa_plot : matplotlib plot figure\n",
        "\t\tMatplotlib plot figure of the DFA\n",
        "\t\"\"\"\n",
        "\t# Check input values\n",
        "\tnn = pyhrv.utils.check_input(nn, rpeaks)\n",
        "\n",
        "\t# Check intervals\n",
        "\tshort = pyhrv.utils.check_interval(short, default=(4, 16))\n",
        "\tlong = pyhrv.utils.check_interval(long, default=(17, 64))\n",
        "\n",
        "\t# Create arrays\n",
        "\tshort = range(short[0], short[1] + 1)\n",
        "\tlong = range(long[0], long[1] + 1)\n",
        "\n",
        "\t# try:\n",
        "\t# Compute alpha values\n",
        "\ttry:\n",
        "\t\talpha1, dfa_short = nolds.dfa(nn, short, debug_data=True, overlap=False)\n",
        "\t\talpha2, dfa_long = nolds.dfa(nn, long, debug_data=True, overlap=False)\n",
        "\texcept ValueError:\n",
        "\t\t# If DFA could not be conducted due to insufficient number of NNIs, return an empty graph and 'nan' for alpha1/2\n",
        "\t\twarnings.warn(\"Not enough NNI samples for Detrended Fluctuations Analysis.\")\n",
        "\t\t# ax.axis([0, 1, 0, 1])\n",
        "\t\t# ax.text(0.5, 0.5, '[Insufficient number of NNI samples for DFA]', horizontalalignment='center',\n",
        "\t\t# \t\tverticalalignment='center')\n",
        "\t\talpha1, alpha2 = 'nan', 'nan'\n",
        "\telse:\n",
        "\t\t# Plot DFA results if number of NNI were sufficent to conduct DFA\n",
        "\t\t# Plot short term DFA\n",
        "\t\tvals, flucts, poly = dfa_short[0], dfa_short[1], np.polyval(dfa_short[2], dfa_short[0])\n",
        "\t\tlabel = r'$ \\alpha_{1}: %0.2f$' % alpha1\n",
        "\t\t# ax.plot(vals, flucts, 'bo', markersize=1)\n",
        "\t\t# ax.plot(vals, poly, 'b', label=label, alpha=0.7)\n",
        "\n",
        "\t\t# Plot long term DFA\n",
        "\t\tvals, flucts, poly = dfa_long[0], dfa_long[1], np.polyval(dfa_long[2], dfa_long[0])\n",
        "\t\tlabel = r'$ \\alpha_{2}: %0.2f$' % alpha2\n",
        "\t\t# ax.plot(vals, flucts, 'go', markersize=1)\n",
        "\t\t# ax.plot(vals, poly, 'g', label=label, alpha=0.7)\n",
        "\n",
        "\t\t# # Add legend\n",
        "\t\t# if legend:\n",
        "\t\t# \tax.legend()\n",
        "\t\t# ax.grid()\n",
        "\n",
        "\t# # Plot axis\n",
        "\t# if show:\n",
        "\t# \tplt.show()\n",
        "\n",
        "\t# Output\n",
        "\targs = (alpha1, alpha2, short, long)\n",
        "\treturn biosppy.utils.ReturnTuple(args, ('dfa_alpha1', 'dfa_alpha2', 'dfa_alpha1_beats', 'dfa_alpha2_beats'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGVjcW24PYNx"
      },
      "source": [
        "non_linear_domain = ['SD1','SD2','SD1/SD2', 'Alpha']\n",
        "\n",
        "original_dfa = nl.dfa\n",
        "nl.dfa = new_dfa\n",
        "\n",
        "def get_non_linear_domain_analysis_features(rr_interval):\n",
        "  result = {}\n",
        "  # plot_poincare(rr_interval)\n",
        "  non_linear_domain_features = get_poincare_plot_features(rr_interval)\n",
        "  features = {'SD1':'sd1',\n",
        "        'SD2': 'sd2'}\n",
        "  for description, key in features.items():\n",
        "    result[description] = non_linear_domain_features[key]\n",
        "\n",
        "  result['SD1/SD2'] = result['SD1'] / result['SD2']\n",
        "\n",
        "  result['Alpha'] = nl.dfa(nn=rr_interval, long=(17,20), show=False)['dfa_alpha1']\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqLQ_DQt57Rs"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHaz3uv7FmCt"
      },
      "source": [
        "def feature_extraction(path, files, time_duration, target, frequency_sampling=128):\n",
        "  features_result = []\n",
        "  errors = []\n",
        "\n",
        "  bar = tqdm(total=len(files))\n",
        "  for no, file in enumerate(files): # Iterate all files\n",
        "    peaklist_df = pd.read_csv(path + file) # in dataframe\n",
        "    peaklist = get_sliced_peaklist(peaklist_df, time_duration, frequency_sampling)\n",
        "    rr_interval = get_rr_interval(peaklist, frequency_sampling)\n",
        "\n",
        "    extracted_features = {}\n",
        "    try:\n",
        "      extracted_features.update(get_time_domain_analysis_features(rr_interval)) # Time Domain Analysis\n",
        "      # extracted_features.update(get_frequency_domain_analysis_features(rr_interval)) # Frequency Domain Analysis\n",
        "      extracted_features.update(get_frequency_domain_analysis_features(rr_interval, 'welch')) # Frequency Domain Analysis\n",
        "      extracted_features.update(get_non_linear_domain_analysis_features(rr_interval)) # Non Linear Domain Analysis\n",
        "      extracted_features.update({'Target': target})\n",
        "      extracted_features.update({'File': file})\n",
        "      features_result.append(extracted_features)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      errors.append(file)\n",
        "    bar.update(1)\n",
        "    # print(\"\\r\", end='')\n",
        "    # print(\"{}/{}\". format(no+1, len(files)), end='', flush=True)\n",
        "  bar.close()\n",
        "  # print(\"\\nDONE!\", end='\\n', flush=False)\n",
        "\n",
        "  return features_result, errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hore7MMfrzu-"
      },
      "source": [
        "def make_dataset(positive_dataset, negative_dataset, columns_order, n_data = 150):\n",
        "  dataset = []\n",
        "  for i in range(n_data):\n",
        "    dataset.append(positive_dataset[i])\n",
        "    dataset.append(negative_dataset[i])\n",
        "  df = pd.DataFrame(dataset)\n",
        "  df = df[columns_order]\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTvlB-EiL0Qi"
      },
      "source": [
        "def save_feature_extraction(dataset, folder, filename):\n",
        "  path = \"/content/drive/My Drive/Signal/\" + folder + \"/\" + filename\n",
        "  dataset.to_csv(path, index=False)\n",
        "  print(\"{} saved!\".format(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2iuPCozJvbe"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def foo_():\n",
        "    time.sleep(0.3)\n",
        "range_ = range(0, 10)\n",
        "total = len(range_)\n",
        "\n",
        "with tqdm(total=total, position=0, leave=True) as pbar:\n",
        "   for i in tqdm((foo_, range_ ), position=0, leave=True):\n",
        "    pbar.update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4PGO_N2JQbW"
      },
      "source": [
        "folder = \"Dataset\"\n",
        "n_data = len(positive_files)\n",
        "columns = time_domain + frequency_domain + non_linear_domain\n",
        "columns.append('Target')\n",
        "columns.append('File')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('once')\n",
        "\n",
        "time_durations = [2,3,4,5] # in minutes\n",
        "for time_duration in time_durations:\n",
        "  # print(\"Positive Dataset Extraction\")\n",
        "  positive_dataset, positive_errors = feature_extraction(positive_path, positive_files[:n_data], time_duration, target = 1)\n",
        "  # print(\"Negative Dataset Extraction\")\n",
        "  negative_dataset, negative_errors = feature_extraction(negative_path, negative_files[:n_data], time_duration, target = 0)\n",
        "  dataset = make_dataset(positive_dataset, negative_dataset,columns_order = columns, n_data=n_data)\n",
        "  save_feature_extraction(dataset, folder, filename = \"Dataset_{}.csv\".format(time_duration))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}