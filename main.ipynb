{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206c5fc2-54ff-4bd9-85dc-5c969b89dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb, wfdb.processing, heartpy\n",
    "from biosppy.signals import ecg\n",
    "from numpy import ndarray\n",
    "from pandas import read_csv as rcsv\n",
    "\n",
    "import json, re\n",
    "from time import time as t\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from wf_preproc import show_ann_label, get_db, extract_ann, extract_rdheader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99235b37-b0c1-4961-8b21-341ac62d473a",
   "metadata": {},
   "source": [
    "EDA on VFDB: https://www.kaggle.com/code/kooaslansefat/eda-on-mit-bih-malignant-ventricular-fibrill-db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a557bc24-49cf-4b23-bd4e-770281cc4ed8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wfdb.io.show_ann_labels()\n",
    "# wfdb.io.show_ann_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d9637e-ff2d-4838-a394-723fe25f584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_dataset = rcsv(\"sample_p10_sensor_outputs.csv\")\n",
    "# (6000 / sample_dataset[\"HR (bpm)\"]).tolist() # 6000 (in miliseconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4330864-33e7-4c30-b0c6-6a8916b0ceed",
   "metadata": {},
   "source": [
    "* \"vfdb\" = **MIT-BIH Malignant Ventricular Ectopy Database**\n",
    "* \"nsrdb\" = **MIT-BIH Normal Sinus Rhythm Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c39b0e-e90b-46c7-b1c6-6621dfdacec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_NAME: MIT-BIH Malignant Ventricular Ectopy Database\n",
      "TOTAL_RECORDS: 22\n"
     ]
    }
   ],
   "source": [
    "dataset = get_db(key=\"vfdb\")\n",
    "db, records = dataset[\"db\"], dataset[\"records\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0dd2b7-e9c4-4efe-bdc8-75df6fee048e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_name</th>\n",
       "      <th>sig_len</th>\n",
       "      <th>sampling_freq</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>418</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>421</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>422</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>423</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>424</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>425</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>426</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>427</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>428</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>429</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>430</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>602</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>605</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>607</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>609</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>610</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>611</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>612</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>614</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>615</td>\n",
       "      <td>525000</td>\n",
       "      <td>250</td>\n",
       "      <td>1990-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    r_name  sig_len  sampling_freq           created_at\n",
       "0      418   525000            250  1990-01-04 00:00:00\n",
       "1      419   525000            250  1990-01-04 00:00:00\n",
       "2      420   525000            250  1990-01-04 00:00:00\n",
       "3      421   525000            250  1990-01-04 00:00:00\n",
       "4      422   525000            250  1990-01-04 00:00:00\n",
       "5      423   525000            250  1990-01-04 00:00:00\n",
       "6      424   525000            250  1990-01-04 00:00:00\n",
       "7      425   525000            250  1990-01-04 00:00:00\n",
       "8      426   525000            250  1990-01-04 00:00:00\n",
       "9      427   525000            250  1990-01-04 00:00:00\n",
       "10     428   525000            250  1990-01-04 00:00:00\n",
       "11     429   525000            250  1990-01-04 00:00:00\n",
       "12     430   525000            250  1990-01-04 00:00:00\n",
       "13     602   525000            250  1990-01-04 00:00:00\n",
       "14     605   525000            250  1990-01-04 00:00:00\n",
       "15     607   525000            250  1990-01-04 00:00:00\n",
       "16     609   525000            250  1990-01-04 00:00:00\n",
       "17     610   525000            250  1990-01-04 00:00:00\n",
       "18     611   525000            250  1990-01-04 00:00:00\n",
       "19     612   525000            250  1990-01-04 00:00:00\n",
       "20     614   525000            250  1990-01-04 00:00:00\n",
       "21     615   525000            250  1990-01-04 00:00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = rcsv(\"data/vfdb-rdheader.csv\")\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cb4215-5d18-4627-bd08-a1950fee06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = rcsv(\"data/vfdb-rdann.csv\")\n",
    "\n",
    "# preprocess the annotation label\n",
    "annotations.annot_aux = annotations.annot_aux.apply(\n",
    "    lambda x: x.replace('(', '').replace('NSR', 'N').replace('VFIB', 'VF')\n",
    ")\n",
    "\n",
    "# set annotations index \"from\" and \"to\"\n",
    "annotations.rename(columns={\"annot_idx\" : \"annot_idx_from\"}, inplace=True)\n",
    "annotations.insert(\n",
    "    column = \"annot_idx_to\",\n",
    "    loc = len(annotations.columns)-1,\n",
    "    value = annotations.groupby('r_name').annot_idx_from.shift(periods = -1, fill_value = -1).astype(int)\n",
    ")\n",
    "\n",
    "# remove last row from each r_name\n",
    "annotations = annotations[annotations.annot_idx_to != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d145c024-e1e7-4ff1-997f-f2f3fe5a8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = wfdb.rdrecord(records[0], channels=[0, 1], pn_dir=db)\n",
    "a = wfdb.rdann(record_name=records[0], pn_dir=db, extension='atr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87aad51f-666e-4930-91f5-f00a6a465435",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'record_name': '418',\n",
       " 'extension': 'atr',\n",
       " 'sample': array([    18,  99624, 101499, 133092, 134038, 135775, 136628, 153057,\n",
       "        154115, 154942, 156291, 159442, 160516, 169192, 169807, 173054,\n",
       "        173673, 174788, 175403, 176259, 177868, 190080, 191249, 191807,\n",
       "        192695, 195631, 196794, 200211, 200634, 216788, 219038, 219961,\n",
       "        224019, 225355, 226057, 227211, 229269, 231310, 232724, 234499,\n",
       "        235538, 254230, 255365, 256019, 256884, 257249, 257980, 259557,\n",
       "        261903, 262749, 263519, 269307, 270999, 271326, 271596, 272057,\n",
       "        272384, 273673, 275846, 279576, 281384, 289384, 291211, 300480,\n",
       "        301076, 301525, 301711, 302230, 302538, 302871, 303346, 303641,\n",
       "        304634, 311442, 311807, 312096, 313480, 313826, 314173, 314493,\n",
       "        316807, 317237, 317480, 318682, 319769, 327480, 329038, 329365,\n",
       "        329749, 333826, 334211, 339769, 340019, 346634, 347038, 347403,\n",
       "        347730, 357634, 358403, 362711, 363115, 367749, 368134, 368583,\n",
       "        369211, 370153, 370557, 370971, 371653, 372041, 372692, 373076,\n",
       "        374961, 384096, 384942, 386903, 389365, 396833, 397249, 400769,\n",
       "        401423], dtype=int64),\n",
       " 'symbol': ['+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+',\n",
       "  '+'],\n",
       " 'subtype': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'chan': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'num': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'aux_note': ['(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00',\n",
       "  '(VFL\\x00',\n",
       "  '(N\\x00'],\n",
       " 'fs': 250,\n",
       " 'label_store': None,\n",
       " 'description': None,\n",
       " 'custom_labels': None,\n",
       " 'contained_labels': None,\n",
       " 'ann_len': 121}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b87ce08c-c9ba-462b-9438-84a354a543a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The length of the ylabel must be the same as the signal: 3 values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wfdb\u001b[38;5;241m.\u001b[39mplot_wfdb(record\u001b[38;5;241m=\u001b[39mr, annotation\u001b[38;5;241m=\u001b[39ma, time_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\MIT-BIH\\mit-bih-venv\\lib\\site-packages\\wfdb\\plot\\plot.py:986\u001b[0m, in \u001b[0;36mplot_wfdb\u001b[1;34m(record, annotation, plot_sym, time_units, title, sig_style, ann_style, ecg_grids, figsize, return_fig, sharex)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m     ann_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_items\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_samp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_samp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_sym\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_sym\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mylabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrecord_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43msig_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43msig_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mecg_grids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecg_grids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\MIT-BIH\\mit-bih-venv\\lib\\site-packages\\wfdb\\plot\\plot.py:309\u001b[0m, in \u001b[0;36mplot_items\u001b[1;34m(signal, ann_samp, ann_sym, fs, time_units, sig_name, sig_units, xlabel, ylabel, title, sig_style, ann_style, ecg_grids, figsize, sharex, sharey, return_fig, return_fig_axes, sampling_freq, ann_freq)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ylabel:\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ylabel) \u001b[38;5;241m!=\u001b[39m n_subplots:\n\u001b[1;32m--> 309\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    310\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of the ylabel must be the same as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_subplots)\n\u001b[0;32m    312\u001b[0m             )\n\u001b[0;32m    314\u001b[0m     _label_figure(\n\u001b[0;32m    315\u001b[0m         axes,\n\u001b[0;32m    316\u001b[0m         n_subplots,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m         title,\n\u001b[0;32m    323\u001b[0m     )\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
      "\u001b[1;31mException\u001b[0m: The length of the ylabel must be the same as the signal: 3 values"
     ]
    }
   ],
   "source": [
    "wfdb.plot_wfdb(record=r, annotation=a, time_units=\"samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcc958-4464-452d-8551-12eaad161686",
   "metadata": {},
   "source": [
    "* remember: f = N/t, where f = sampling frequency, N = signal length, t = time\n",
    "* time_per_second = signal_len / sampling_freq = 525000/250 = 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "310ff97d-83d1-42ab-a898-4e2f9571b9de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# record_num = 418\n",
    "# for _, i in annotations[annotations.r_name == record_num].iterrows():\n",
    "#     if _ > 50:\n",
    "#         FS = header[header.r_name == record_num].sampling_freq.squeeze()\n",
    "#         from_idx = i.annot_idx_from\n",
    "#         to_idx = i.annot_idx_to\n",
    "\n",
    "#         ann = wfdb.rdann(record_name=str(record_num), sampfrom=from_idx, sampto=to_idx+FS, extension=\"atr\", pn_dir=db)\n",
    "#         print(ann.sample)\n",
    "#         rr_interval = wfdb.processing.calc_rr(ann.sample, fs=FS)\n",
    "#         rr_interval = np.insert(rr_interval, 0, ann.sample[0]) if from_idx == 1 else rr_interval\n",
    "#             # np.insert() is used to add the first annotation sample (i.e., ann.sample[0]), only when annot_idx = 1\n",
    "#         rr_interval = rr_interval # / ann.fs # normalize\n",
    "#         print(\"f={}, t={} {}\".format(from_idx, to_idx, rr_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45e2938-169c-4ca8-84eb-8a55b2a90937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record_start_partitions(\n",
    "    record : str,\n",
    "    db : str,\n",
    "    min_duration : int,\n",
    "    freq_rate : int,\n",
    "    resampling : int = 0,\n",
    "    *args, **kwargs\n",
    ") -> dict:\n",
    "    \n",
    "    def get_label(annotation):\n",
    "        p = re.compile(\"([A-Za-z]+)\")\n",
    "        return p.search(annotation)[1]\n",
    "    \n",
    "    start_sample = (min_duration * 60) * freq_rate # freq = N / time(s), therefore N = freq x time\n",
    "    annotation = wfdb.rdann(record, 'atr', pn_dir=db, sampfrom=start_sample)\n",
    "    signals, _ = wfdb.rdsamp(record, pn_dir=db, sampfrom=start_sample)\n",
    "    \n",
    "    if resampling != 0:\n",
    "        start_sample = (min_duration * 60) * resampling\n",
    "        signals, annotation = wfdb.processing.resample_multichan(\n",
    "            signals, annotation, freq_rate, resampling)\n",
    "    \n",
    "    annotations = [get_label(a) for a in annotation.aux_note]\n",
    "    annotations = list(map(lambda x: x.replace('NSR', 'N').replace('VFIB', 'VF'), annotations))\n",
    "    \n",
    "    positive_labels = [\"VT\", \"VF\", \"VFL\"]\n",
    "    negative_labels = [\"N\"] # normal rhythm\n",
    "    \n",
    "    results_pos = []\n",
    "    results_neg = []\n",
    "    \n",
    "    for ann, annot_sample in zip(annotations, annotation.sample):\n",
    "        if ann in positive_labels:\n",
    "            results_pos.append(annot_sample-start_sample) # n sample before events\n",
    "        elif ann in negative_labels:\n",
    "            results_neg.append(annot_sample-start_sample)\n",
    "    \n",
    "    results_pos = [r for r in results_pos if r > 0] # remove non-negative values\n",
    "    results_neg = [r for r in results_neg if r > 0] # remove non-negative values\n",
    "    \n",
    "    return {\"positive\" : results_pos, \"negative\" : results_neg}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6dbf8-72c8-4a86-8c33-2b4717f7d9e8",
   "metadata": {},
   "source": [
    "### Preprocessing (R-R Interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a0a706-d111-4685-b365-9d611207b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a9361c9-defa-4541-9fa2-53bc9f54f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalPreprocessing():\n",
    "    def __init__(self, record_idx : str, db : str, *args, **kwargs) -> None:\n",
    "        super(SignalPreprocessing, self).__init__()\n",
    "        self.record_idx = record_idx\n",
    "        self.db = db\n",
    "        \n",
    "        # record\n",
    "        self.r = wfdb.rdrecord(record_name=self.record_idx, pn_dir=self.db)\n",
    "        \n",
    "        # annotation\n",
    "        self.a = wfdb.rdann(record_name=self.record_idx, pn_dir=self.db, extension='atr')\n",
    "        \n",
    "        self.signals = self.r.p_signal # can be multi-dimensional channels\n",
    "        self.channels = self.r.sig_name\n",
    "        self.freq_rate = self.r.fs\n",
    "        \n",
    "    def extract_rpeaks(self, signal, *args, **kwargs) -> ndarray:\n",
    "        # segment\n",
    "        rpeaks, = ecg.engzee_segmenter(\n",
    "            signal=signal,\n",
    "            sampling_rate=self.freq_rate\n",
    "        )\n",
    "\n",
    "        # correct R-peak locations\n",
    "        rpeaks, = ecg.correct_rpeaks(\n",
    "            signal=signal, rpeaks=rpeaks,\n",
    "            sampling_rate=self.freq_rate, tol=.05\n",
    "        )\n",
    "\n",
    "        # extract templates\n",
    "        _, rpeaks = ecg.extract_heartbeats(\n",
    "            signal=signal, rpeaks=rpeaks,\n",
    "            sampling_rate=self.freq_rate, before=.2, after=.4\n",
    "        )\n",
    "        \n",
    "        return rpeaks\n",
    "        \n",
    "    def filter_signal(self, signal, low_freq, high_freq, *args, **kwargs) -> ndarray:\n",
    "        return heartpy.filter_signal(\n",
    "            signal, filtertype='bandpass',\n",
    "            cutoff=[low_freq, high_freq], sample_rate=self.freq_rate\n",
    "        )\n",
    "    \n",
    "    def get_peaklist(self,\n",
    "        start_partitions : list,\n",
    "        duration : int,\n",
    "        label : int,\n",
    "        resampling : int = 0,\n",
    "        *args, **kwargs\n",
    "    ) -> dict:\n",
    "        '''\n",
    "        Example return:\n",
    "        return_example = {\n",
    "            \"peaks\" : {\n",
    "                1000 : [\n",
    "                    {\"channel\" : \"ECG1\", \"value\" : [20, 30, 40]},\n",
    "                    {\"channel\" : \"ECG2\", \"value\" : [50, 60, 70]},\n",
    "                ],\n",
    "                2500 : [\n",
    "                    {\"channel\" : \"ECG1\", \"value\" : [55, 66, 77]},\n",
    "                    {\"channel\" : \"ECG2\", \"value\" : [75, 85, 96]},\n",
    "                ]\n",
    "            }, \n",
    "            \"created_at\" : \"2024-02-15\", \n",
    "            \"exc_time\" : 50.184\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        # to calculate exc. time (in seconds)\n",
    "        start_time = t()\n",
    "        \n",
    "        # reassign variables since they can be overrided if resampling != 0\n",
    "        fr = self.freq_rate\n",
    "        signals = self.signals\n",
    "        \n",
    "        # resampling signal (if any)\n",
    "        if resampling != 0:\n",
    "            resampled_signals, _ = wfdb.processing.resample_multichan(\n",
    "                self.signals, self.a, fr, resampling\n",
    "            )\n",
    "            fr = resampling\n",
    "            signals = resampled_signals\n",
    "            \n",
    "            # if you did resampling, partitions index should be adjusted\n",
    "            # based on the newest max. signal length.\n",
    "            start_partitions = [i for i in start_partitions if i <= len(signals)]\n",
    "        \n",
    "        FINAL_RESULTS, PARTITION = {}, {}\n",
    "        for start_partition in start_partitions:\n",
    "            delta = (duration * 60) * fr # remember, freq = N / time(s), therefore N = freq x time\n",
    "            curr_signals = signals[start_partition:start_partition+delta, :]\n",
    "            \n",
    "            PEAKS_CHANNEL = []\n",
    "            for i, channel in enumerate(self.channels):\n",
    "                signal = curr_signals[:, i]\n",
    "                signal = self.filter_signal(signal, 7, 30) # filtered\n",
    "                peaks = self.extract_rpeaks(signal)\n",
    "                peaks = [int(p) for p in peaks] # convert from np.int32 to INT\n",
    "                PEAKS_CHANNEL.append(dotdict({\"channel\" : channel, \"value\" : peaks}))\n",
    "            PARTITION[int(start_partition)] = PEAKS_CHANNEL\n",
    "        \n",
    "        FINAL_RESULTS[\"peaks\"] = PARTITION\n",
    "        FINAL_RESULTS[\"label\"] = label\n",
    "        FINAL_RESULTS[\"exc_time\"] = round(t()-start_time, 3)\n",
    "        FINAL_RESULTS[\"created_at\"] = dt.now().strftime(\"%Y-%m-%d %X\")\n",
    "        \n",
    "        return dotdict(FINAL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "483bfab4-43cf-421a-86cf-38ab0e5fd954",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(records, header):\n",
    "    for r in records:\n",
    "        FS = header[header.r_name == int(r)].sampling_freq.squeeze()\n",
    "        st = get_record_start_partitions(record=r, db=db, min_duration=5, freq_rate=FS)\n",
    "        proc = SignalPreprocessing(record_idx=r, db=db)\n",
    "\n",
    "        # Positive label\n",
    "        partition_pos = st[\"positive\"]\n",
    "        result_pos = proc.get_peaklist(start_partitions=partition_pos, duration=5, label=1)\n",
    "        with open(\"data/positive/{}.json\".format(r), \"w\") as outfile: \n",
    "            json.dump(result_pos, outfile)\n",
    "        print(\"Record {} (positive) was completed.\".format(r))\n",
    "\n",
    "        # Negative label\n",
    "        partition_neg = st[\"negative\"]\n",
    "        result_neg = proc.get_peaklist(start_partitions=partition_neg, duration=5, label=0)\n",
    "        with open(\"data/negative/{}.json\".format(r), \"w\") as outfile: \n",
    "            json.dump(result_neg, outfile)  \n",
    "        print(\"Record {} (negative) was completed.\".format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73140882-79be-4e91-b2aa-ccaf6bd0b62b",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa16eac-3e4b-40ea-ad70-f0fb663e49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heartpy import analysis\n",
    "import hrvanalysis as hrva\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c9e94f3-fd5e-4541-b8fd-db23c22daf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pos_filepath = [\"data/positive/{}\".format(p) for p in os.listdir(\"data/positive\") if p.endswith(\".json\")]\n",
    "dataset_neg_filepath = [\"data/negative/{}\".format(p) for p in os.listdir(\"data/negative\") if p.endswith(\".json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3475cda-42ad-4158-b179-353340851a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_preproc(rr_interval : list) -> list:\n",
    "    nn_interval = hrva.remove_outliers(rr_intervals=rr_interval, verbose=False)\n",
    "\n",
    "    # @param method: \"malik\", \"kamath\", \"karlsson\", \"acar\"\n",
    "    nn_interval = hrva.remove_ectopic_beats(rr_intervals=nn_interval, method=\"malik\", verbose=False)\n",
    "\n",
    "    # @param interpolation_method: 'linear', 'time', 'index', 'values', 'nearest', 'zero', 'slinear',\n",
    "    # 'quadratic', 'cubic', 'barycentric', 'krogh', 'spline', 'polynomial', 'from_derivatives',\n",
    "    # 'piecewise_polynomial', 'pchip', 'akima', 'cubicspline'\n",
    "    nn_interval = hrva.interpolate_nan_values(rr_intervals=nn_interval, interpolation_method=\"cubic\")\n",
    "\n",
    "    # remove NaN values which weren't filtered during interpolation; e.g., in the last index\n",
    "    nn_interval = [i for i in nn_interval if str(i) != \"nan\"]\n",
    "    \n",
    "    return nn_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02dec9d9-05b8-4a54-9c46-13d6d511755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RECORDS = []\n",
    "for filepath in (dataset_pos_filepath+dataset_neg_filepath): # LOOP per file\n",
    "    with open(filepath) as file:\n",
    "        data = json.load(fp=file)\n",
    "\n",
    "    for idx in data[\"peaks\"].keys(): # LOOP per start_partition\n",
    "        for ch_num, ch in enumerate(data[\"peaks\"][idx]): # LOOP per channel\n",
    "            peaklist = ch[\"value\"]\n",
    "            rr = analysis.calc_rr(peaklist=peaklist, sample_rate=250)\n",
    "            nn_interval = rr_preproc(rr_interval=rr[\"RR_list\"])\n",
    "\n",
    "            FEATURES = {\n",
    "                \"record_id\" : int(filepath.split(\"/\")[-1].split(\".json\")[0]),\n",
    "                \"start_partition_idx\" : idx,\n",
    "                \"channel\" : ch[\"channel\"] + \"_{}\".format(str(ch_num))\n",
    "            }\n",
    "\n",
    "            # Reference:\n",
    "            # 1. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5624990/\n",
    "            # 2. https://aura-healthcare.github.io/hrv-analysis/hrvanalysis.html\n",
    "            \n",
    "            # TIME DOMAIN\n",
    "            ftr_time_domain = hrva.get_time_domain_features(nn_interval)\n",
    "            FEATURES.update(ftr_time_domain)\n",
    "\n",
    "            ftr_geometric_time_domain = hrva.get_geometrical_features(nn_interval)\n",
    "            FEATURES.update(ftr_geometric_time_domain)\n",
    "\n",
    "            # Frequency Domain\n",
    "            ftr_freq_domain = hrva.get_frequency_domain_features(nn_interval)\n",
    "            FEATURES.update(ftr_freq_domain)\n",
    "\n",
    "            # Non-linear Domain\n",
    "            ftr_entropy = hrva.get_sampen(nn_interval) # sample entropy\n",
    "            FEATURES.update({\"entropy\" : ftr_entropy[\"sampen\"]})\n",
    "\n",
    "            ftr_poincare = hrva.get_poincare_plot_features(nn_interval)\n",
    "            FEATURES.update(ftr_poincare)\n",
    "\n",
    "            # CVI (Cardiac Sympathetic Index), CSI (Cardiac Vagal Index)\n",
    "            ftr_csi_cvi = hrva.get_csi_cvi_features(nn_interval)\n",
    "            FEATURES.update(ftr_csi_cvi)\n",
    "            \n",
    "            FEATURES.update({\"label\" : int(data[\"label\"])}) # set label\n",
    "            DF_RECORDS.append(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ed4e6-e01b-4c25-923c-bb715df72a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1dec8bc-ae00-49f0-b092-efd921fd0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame as df, read_csv as rcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ed8f1d-782a-4ea1-8eb4-7e398c6fd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vfdb_dataset = df(DF_RECORDS)\n",
    "# vfdb_dataset.to_csv(\"data/vfdb_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a8e2db-7011-4bb0-b15e-bd2344252c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vfdb_dataset = rcsv(\"data/vfdb_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "028877da-7998-4d4a-8b17-12739e8d5489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['record_id', 'start_partition_idx', 'channel', 'mean_nni', 'sdnn',\n",
       "       'sdsd', 'nni_50', 'pnni_50', 'nni_20', 'pnni_20', 'rmssd', 'median_nni',\n",
       "       'range_nni', 'cvsd', 'cvnni', 'mean_hr', 'max_hr', 'min_hr', 'std_hr',\n",
       "       'triangular_index', 'tinn', 'lf', 'hf', 'lf_hf_ratio', 'lfnu', 'hfnu',\n",
       "       'total_power', 'vlf', 'entropy', 'sd1', 'sd2', 'ratio_sd2_sd1', 'csi',\n",
       "       'cvi', 'Modified_csi', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfdb_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7f4e39-4d1b-441c-be58-69f2a6aa70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "432e8f83-7f55-4e31-ac49-4bafc165706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vfdb_dataset[['mean_nni', 'rmssd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44b41339-e6ed-432b-9b61-6b32635c9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = vfdb_dataset.drop([\n",
    "#     \"record_id\", \"start_partition_idx\", \"channel\", \"tinn\", \"sdsd\", \"nni_50\",\n",
    "#     \"pnni_50\", \"nni_20\", \"pnni_20\", \"median_nni\", \"range_nni\", \"cvsd\", \"cvnni\",\n",
    "#     \"max_hr\", \"min_hr\", \"lf\", \"hf\", \"lfnu\", \"hfnu\", \"sd1\", \"sd2\", \"Modified_csi\", \"label\"\n",
    "# ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "685f759b-a32f-4792-a2ad-2c5935e673b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = vfdb_dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55d46d3d-fcc1-45ab-82f7-8fae12b05eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.groupby(\"label\").sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "feceb723-5f35-47c1-b5d1-e6491c4e7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import MinMaxScaler as mms\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve, confusion_matrix as cfmat\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa56ff41-ce47-467c-81bd-e1c09cbc01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd94f814-3c18-4e4d-94b8-5623440fa592",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = mms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63438575-24e1-48f1-90f0-8439bf3ea7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "594c349b-eb1d-4b21-b94f-9c7e43e19ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6292682926829268"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ae68c60-069d-474d-9320-084954f86865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5804878048780487"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256, 64, 32),\n",
    "    batch_size=128,\n",
    "    learning_rate_init=1e-5, learning_rate=\"adaptive\",\n",
    "    early_stopping=True, random_state=42, max_iter=1000\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1bb79ee3-47ac-466c-933e-9da36f90499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.664\n",
      "Recall: 0.687\n",
      "F1-score: 0.675\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cfmat(y_pred, y_test).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1-score: {:.3f}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c08c086b-2267-4a7e-bba5-a13fec153009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6226304475278482"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0817f52-57a8-4614-b2cc-f2c94def0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using RFE\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# a = RFE(estimator=model, n_features_to_select=5)\n",
    "# selector = a.fit(X_train_scaled, y_train)\n",
    "# selector.support_\n",
    "\n",
    "# np.array(X.columns)[np.array(selector.support_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9fbf96-8f28-4d32-b5eb-2303334c414c",
   "metadata": {},
   "source": [
    "### Poincare and PSD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f02731d-d5c2-4001-9590-05120f6808fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hrvanalysis import plot_psd, plot_poincare\n",
    "\n",
    "# plot_poincare(nn_interval, plot_sd_features=True)\n",
    "# plot_psd(nn_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-bih-venv",
   "language": "python",
   "name": "mit-bih-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
